{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-mYY42BSBOi1"
   },
   "source": [
    "# Семантическая Сегментация. Часть 3.\n",
    "\n",
    "Датасет COCO - command objects in context.\n",
    "\n",
    "В ноутбуке пример создания пайплайна данных для датасета COCO. Train датасет весит 18Gb.\n",
    "\n",
    "Не всегда Google Colab предоставляет достаточно места для скачивания датасета. Возможно придётся скачивать датасет на локальную машину и подготовить локально (например отобрать картинки только с определённым классом, например с классом \"человек\"), и подготовленный локально датасет уже загрузить в колаб."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ty18tSuABT9X"
   },
   "source": [
    "## Переключение версии TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fS42SrF5Tm4H"
   },
   "outputs": [],
   "source": [
    "%tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zvoeKMnP0V7j"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import skimage.io as io\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-rSwyWz-BU9t"
   },
   "source": [
    "## Загрузка датасета COCO и COCO API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H306Fzq_0Mzi"
   },
   "outputs": [],
   "source": [
    "if 1:\n",
    "    !mkdir -p data\n",
    "\n",
    "    # !cd data && wget http://images.cocodataset.org/zips/train2017.zip \n",
    "    # !cd data && wget http://images.cocodataset.org/zips/val2017.zip \n",
    "    !cd data && wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip \n",
    "\n",
    "    # !cd data && unzip -q train2017.zip\n",
    "    # !cd data && unzip -q val2017.zip\n",
    "    !cd data && unzip -q annotations_trainval2017.zip\n",
    "\n",
    "    # библиотека для работы с COCO API\n",
    "    !cd data && git clone https://github.com/cocodataset/cocoapi\n",
    "    !cd data/cocoapi/PythonAPI && make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y0xB9xnQBbV2"
   },
   "source": [
    "## Подготовка COCO API\n",
    "\n",
    "Импортируем библиотеку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FLYZPXQg1m94"
   },
   "outputs": [],
   "source": [
    "COCO_ROOT = './data/'\n",
    "import sys\n",
    "sys.path.insert(0, os.path.join(COCO_ROOT, 'cocoapi/PythonAPI'))\n",
    "from pycocotools.coco import COCO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0yLcNgZOBgQ0"
   },
   "source": [
    "## Универсальный класс Dataset для сегментации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bZhpoFlh1rmE"
   },
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "\n",
    "    def crop_images(self, img, inp_size, random_crop=False):\n",
    "        shape = tf.shape(img)\n",
    "        pad = (\n",
    "            [0, tf.maximum(inp_size - shape[0], 0)],\n",
    "            [0, tf.maximum(inp_size - shape[1], 0)],\n",
    "            [0, 0],\n",
    "        )\n",
    "        img = tf.pad(img, pad)\n",
    "\n",
    "        if random_crop:\n",
    "            img = tf.image.random_crop(img, (inp_size, inp_size, shape[2]))\n",
    "        else: # central crop\n",
    "            shape = tf.shape(img)\n",
    "            ho = (shape[0] - inp_size) // 2\n",
    "            wo = (shape[1] - inp_size) // 2\n",
    "            img = img[ho:ho+inp_size, wo:wo+inp_size, :]\n",
    "\n",
    "        return img\n",
    "\n",
    "    def train_dataset(self, batch_size, epochs, inp_size):\n",
    "    # картинки разного размера. Чтобы привести их к одному размеру будем делать кроп\n",
    "    # кроп будем производить случайным образом, получится аугументация, что хорошо\n",
    "        def item_to_images(item):\n",
    "            # item - путь к картинке\n",
    "            random_crop = True\n",
    "            # read_images заточена под COCO, читает картинки, передаём путь\n",
    "            # на выходе получаем комбинированную картинку, где по канальному измерению сконкатенирована\n",
    "            # поканальная картинка RGB и картинка с метками классов (картинки будут иметь тип tf.uint8)\n",
    "            img_combined = tf.py_function(self.read_images, [item], tf.uint8)\n",
    "            # вызываем кроп не заботясь о том, чтобы соответствовали исходная картинка и ground truth,\n",
    "            # потому что получается 4-х канальная картинка\n",
    "            # если random_crop, то берём случайный кроп с фиксированным размером, иначе центральный\n",
    "            img_combined = self.crop_images(img_combined, inp_size, random_crop)\n",
    "            \n",
    "            # получаем картинку и маску (карту сегментации - ground truth)\n",
    "            # исходная картинка в первых 3-х каналах img_combined, преобразуем во float32 и делим на 255\n",
    "            img = tf.cast(img_combined[...,:3], tf.float32) / np.float32(255.)\n",
    "            # маску (сегментацию) извлекаем из последнего канала img_combined, который переводим в float32\n",
    "            mask_class = tf.cast(img_combined[...,3:4], tf.float32)\n",
    "            return img, mask_class\n",
    "\n",
    "        # датасет - это список путей к файлам с картинками\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(self.img_list)\n",
    "        # перемешиваем пути. you have a dataset: [1, 2, 3, 4, 5, 6], then .shuffle(buffer_size=3) will allocate\n",
    "        # a buffer of size 3 for picking random entries. This buffer will be connected to the source dataset\n",
    "        # https://stackoverflow.com/questions/53514495/what-does-batch-repeat-and-shuffle-do-with-tensorflow-dataset\n",
    "        dataset = dataset.shuffle(buffer_size=len(self.img_list))\n",
    "        # для каждого элемента датасета применяем функцию item_to_images и получаем выход для каждого элемента\n",
    "        # т.е. она по item читает картинку с диска и отдаёт изображение и карту сегментации\n",
    "        dataset = dataset.map(item_to_images)\n",
    "        # повторяем столько раз сколько эпох. As soon as all the entries are read from the dataset and you try\n",
    "        # to read the next element, the dataset will throw an error. That's where ds.repeat() comes into play.\n",
    "        # It will re-initialize the dataset, making it again like this: [1,2,3] <= [4,5,6]\n",
    "        dataset = dataset.repeat(epochs)\n",
    "        # The .batch() will take first batch_size entries and make a batch out of them. So, batch size of 3 for\n",
    "        # our example dataset will produce two batch records:[2,1,5][3,6,4]\n",
    "        dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "        return dataset\n",
    "\n",
    "    def val_dataset(self, batch_size, inp_size):\n",
    "        # на валидационном датасети нельзя делать случайный кроп, поэтому здесь всегда\n",
    "        # будет кроп из центра: random_crop = False и мы не делаем repeat по эпохам\n",
    "        # просто датасет как есть\n",
    "\n",
    "        def item_to_images(item):\n",
    "            random_crop = False\n",
    "            img_combined = tf.py_function(self.read_images, [item], tf.uint8)\n",
    "            img_combined = self.crop_images(img_combined, inp_size, random_crop)\n",
    "\n",
    "            img = tf.cast(img_combined[...,:3], tf.float32) / np.float32(255.)\n",
    "            mask_class = tf.cast(img_combined[...,3:4], tf.float32)\n",
    "            return img, mask_class\n",
    "\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(self.img_list)\n",
    "        dataset = dataset.map(item_to_images)\n",
    "        dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZPXZGUhHBn3Q"
   },
   "source": [
    "## Класс для сегментационного датасета COCO\n",
    "\n",
    "Класс наследутся от универсального `Dataset` и реализует кастомную функцию чтения данных. Здесь специфичная для COCO логика."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MjYwt86l1xMt"
   },
   "outputs": [],
   "source": [
    "class COCO_Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, sublist):\n",
    "        # путь к разметке\n",
    "        ann_file_fpath = os.path.join(COCO_ROOT, 'annotations', 'instances_'+sublist+'2017.json')\n",
    "        # инициализируем класс COCO из COCO API\n",
    "        self.coco = COCO(ann_file_fpath)\n",
    "        # указываем какие категории мы хоти указывать (можно несколько в списке)\n",
    "        self.cat_ids = self.coco.getCatIds(catNms=['person'])\n",
    "        # с помощью COCO API получаем список картинок с категориями\n",
    "        self.img_list = self.coco.getImgIds(catIds=self.cat_ids)\n",
    "\n",
    "    def read_images(self, img_id):\n",
    "        # функция для загрузки картинок по img_id (элементу списка img_list)\n",
    "        img_id = int(img_id.numpy())\n",
    "        # получаем картинку по img_id\n",
    "        img_data = self.coco.loadImgs(img_id)[0]\n",
    "        img_fname = '/'.join(img_data['coco_url'].split('/')[-2:])\n",
    "\n",
    "        # логика по загрузке масок\n",
    "        # в аннтоации может быть несколько масок по числу людей и каждая маска сидит в отдельном слое\n",
    "        # плюсуем все маски в одну\n",
    "        img = io.imread(os.path.join(COCO_ROOT, img_fname))\n",
    "        if len(img.shape) == 2:\n",
    "            img = np.tile(img[..., None], (1, 1, 3))\n",
    "\n",
    "        ann_ids = self.coco.getAnnIds(imgIds=img_data['id'], catIds=self.cat_ids, iscrowd=None)\n",
    "        anns = self.coco.loadAnns(ann_ids)\n",
    "        mask_class = np.zeros((img.shape[0], img.shape[1]), dtype=np.uint8)\n",
    "        for i in range(len(anns)):\n",
    "            mask_class += self.coco.annToMask(anns[i])\n",
    "        mask_class = (mask_class > 0).astype(np.uint8)\n",
    "        # получаем бинарную маску человек/фон даже если несколько людей\n",
    "\n",
    "        # получаем картинку вместе с маской сегментации\n",
    "        img_combined = np.concatenate([img, mask_class[..., None]], axis=2)\n",
    "\n",
    "        return img_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cdevykTc1zWz"
   },
   "outputs": [],
   "source": [
    "# создаём train и валидационный датасеты\n",
    "# строка train и val передаётся в COCO Dataset конструктор для чтения нужного json-файла\n",
    "COCO_dataset_train = COCO_Dataset('train')\n",
    "COCO_dataset_val = COCO_Dataset('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1c-9GNjZJiAd"
   },
   "outputs": [],
   "source": [
    "# из COCO датасетов получаем датасеты для tensorflow\n",
    "# train_ds = COCO_dataset_train.train_dataset(...)\n",
    "# val_ds = COCO_dataset_val.val_dataset(...)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "4_3_Segmentation_COCO.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
