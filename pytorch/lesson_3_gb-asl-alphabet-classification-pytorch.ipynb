{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предобученные сети, которыми можно пользоваться\n",
    "\n",
    "## LeNet'98\n",
    "\n",
    "LeNet была создана ,чтобы распознавать цифры на почтовых бланках.\n",
    "\n",
    "Особенности LeNet5:\n",
    "\n",
    "- Свёрточная нейросеть, использующая последовательность из трёх слоёв: слои свёртки (convolution), слои группирования (pooling) и слои нелинейности (non-linearity) –> с момента публикации работы Лекуна это, пожалуй, одна из главных особенностей глубокого обучения применительно к изображениям.\n",
    "- Подвыборка с использованием усреднения карт.\n",
    "- Нелинейность в виде гиперболического тангенса или сигмоид (проблема с затухающим градиентом).\n",
    "- Финальный классификатор в виде многослойной нейросети.\n",
    "\n",
    "<img src='https://drive.google.com/uc?exoprt=view&id=1pPe1aBh7ySg89cxbWEZ07iabvvXABUxd'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Многие предобученные модели обучались на датасете ImageNet, который содержит 14,197,122 картинок - это набор данных размечанных изображений с высоким разрешением, относящихся примерно к 22 тысячам категорий. Проводился «Крупномасштабный конкурс визуального распознавания ImageNet» (ILSVRC2013). ILSVRC использует подмножество ImageNet из примерно 1000 изображений в каждой из 1000 категорий.\n",
    "\n",
    "<img src='https://avatars.mds.yandex.net/get-zen_doc/127510/pub_5c33ad37c906e200abbace3b_5c33adfbe5e73b00aad095a1/scale_1200'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet'12\n",
    "\n",
    "В AlexNet результаты вычислений LeNet масштабированы в гораздо более крупную нейросеть, которая способна изучить намного более сложные объекты и их иерархии. Особенности:\n",
    "\n",
    "- Использование блоков ReLU в качестве нелинейностей (нет проблемы с затуханием градиентов).\n",
    "- Использование max pooling, что позволяет избежать эффектов усреднения average pooling.\n",
    "\n",
    "На вход идут картинки 224х224, естественно не все картинки такого размера, поэтому будет достаточно просто сжать их до нужного размера.\n",
    "\n",
    "<img src='https://drive.google.com/uc?export=view&id=1sjEftFGiJ50-m3VevamktVznsx6bY3Yw' width=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG'14\n",
    "В разработанных в Оксфорде VGG-сетях в каждом свёрточном слое впервые применили фильтры 3х3 и объединили эти слои в последовательности свёрток.\n",
    "\n",
    "Вместо применяемых в AlexNet фильтров 9х9 и 11х11 стали применять гораздо более мелкие фильтры, которых старались избежать авторы LeNet. Но большим преимуществом VGG стала находка, что несколько свёрток 3х3, объединённых в последовательность, могут эмулировать более крупные свертки, например, 5х5 или 7х7 (7х7 + 1 байес = 50 обучаемых параметров).\n",
    "\n",
    "Каскад из двух сверток 3х3 равен свертке 5х5, но с меньшим количеством параметров.\n",
    "(5х5 = 25 + 1 = 26; 3x3 + 3x3 + 2 = 20)\n",
    "\n",
    "<img src='https://drive.google.com/uc?export=view&id=1GvrtEDocJ3xp9RKqgQu0-JnyTssqZhzV'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Глубокие сверточные нейронные сети превзошли человеческий уровень классификации изображений в 2015 году. Глубокие сети извлекают низко-, средне- и высокоуровневые признаки  сквозным многослойным способом, а увеличение количества слоев обогатить «уровни» признаков. Но у глубоких нейронных сетей была проблема: затухающие градиенты. Особенно это явно чувствуется с сигмоидой.\n",
    "\n",
    "$d\\sigma = \\sigma(1 - \\sigma) \\leqslant \\frac{1}{4}$\n",
    "\n",
    "<img src='https://drive.google.com/uc?export=view&id=171JbyNkSSqzhPdX4fp439zOouEzJmq_s'>\n",
    "\n",
    "Если постоянно брать производную сигмоиды, то максимальная производная сигмоиды - это 0,25. Если мы будем идти к началу чети, пто 0,25 будет возводиться в степень сколько у нас сигмоид. И это быстро становится близким к нулю. А если градиент равен нулю, то никакого обучения не будет.\n",
    "\n",
    "Кроме того, что можно вместо сигмоиды брать ReLu, можно пробрасывать ошибку."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GoogLeNet\n",
    "\n",
    "Эта сеть использует Inception блоки. Это параллельная комбинация свёрточных фильтров 1х1, 3х3 и 5х5. Но главная особенность заключается в использовании свёрточных блоков 1х1 для уменьшения количества каналов перед подачей в более «дорогие» сверточные блоки. Обычно эту часть называют bottleneck. Вместо использования свертки 5х5 на нашем изображении, можем сначала пройтись сверткой 1х1 уменьшив количество каналов, а затем по ним пройтись сверткой 5х5, вернув количество каналов. Операций будет меньше, а результат будет одинаковый.\n",
    "\n",
    "<img src='https://drive.google.com/uc?export=view&id=1hgoTi6d-pdRPHgnfVGssQIQXBUdrkWrk'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-13T13:42:57.029808Z",
     "iopub.status.busy": "2021-06-13T13:42:57.029553Z",
     "iopub.status.idle": "2021-06-13T13:43:05.74811Z",
     "shell.execute_reply": "2021-06-13T13:43:05.747224Z",
     "shell.execute_reply.started": "2021-06-13T13:42:57.029785Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install torchsummary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-13T13:43:05.751769Z",
     "iopub.status.busy": "2021-06-13T13:43:05.751503Z",
     "iopub.status.idle": "2021-06-13T13:43:06.939399Z",
     "shell.execute_reply": "2021-06-13T13:43:06.938615Z",
     "shell.execute_reply.started": "2021-06-13T13:43:05.751741Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchsummary import summary\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-13T13:43:06.941493Z",
     "iopub.status.busy": "2021-06-13T13:43:06.941149Z",
     "iopub.status.idle": "2021-06-13T13:43:12.143058Z",
     "shell.execute_reply": "2021-06-13T13:43:12.142165Z",
     "shell.execute_reply.started": "2021-06-13T13:43:06.941455Z"
    }
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=256,\n",
    "              out_channels=256,\n",
    "              kernel_size=5)\n",
    ")\n",
    "\n",
    "summary(model.to(device), input_size=(256, 16, 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-13T13:43:12.145155Z",
     "iopub.status.busy": "2021-06-13T13:43:12.144636Z",
     "iopub.status.idle": "2021-06-13T13:43:12.1664Z",
     "shell.execute_reply": "2021-06-13T13:43:12.165628Z",
     "shell.execute_reply.started": "2021-06-13T13:43:12.145114Z"
    }
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=256,\n",
    "              out_channels=128,\n",
    "              kernel_size=1),\n",
    "    nn.Conv2d(in_channels=128,\n",
    "              out_channels=256,\n",
    "              kernel_size=5)\n",
    ")\n",
    "\n",
    "summary(model.to(device), input_size=(256, 16, 16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разработчики этой сети придумали способ, чтобы градиенты не затухали: вводится несколько вспомогательных функций на протяжении всей сети, чтобы когда градиент от первого выхода начинал затухать, подключался градиент со второго выхода.\n",
    "\n",
    "<img src='https://drive.google.com/uc?export=view&id=1q3oJXpwGStYit5Ii13DIsexVqxwIjyjE'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet'15\n",
    "\n",
    "ResNet лучше всех борется с проблемами затухающих градиентов.\n",
    "\n",
    "До этого боролись с затухающими градиентами только за счет ввода другой функции активации.\n",
    "\n",
    "Чтобы преодолеть проблему затухающих градиентов, Microsoft ввела глубокую «остаточную» структуру обучения.\n",
    "\n",
    "<img src='https://drive.google.com/uc?export=view&id=1RGJQl4-SmysYbAqwcy8Lm5qEPbiebZOO'>\n",
    "\n",
    "Смысл:\n",
    "\n",
    "$y = f(x) + x $<br>\n",
    "$dy = df(x) + 1 $<br>\n",
    "<h3>$\\frac{dL}{dx} = \\frac{dL}{dy} \\frac{dy}{dx} = \\frac{dL}{dy}(df(x) + 1 )$</h3><br>\n",
    "\n",
    "То есть градиенты всё равно будут протекать дальше в немного измененном виде.\n",
    "\n",
    "\n",
    "Соединения быстрого доступа (shortcut connections, residual connections) пропускают один или несколько слоев и выполняют сопоставление идентификаторов.\n",
    "\n",
    "<img src='https://drive.google.com/uc?export=view&id=1JcQDIjA-97L2xs3o-JD4SWBld9J0OMW-'>\n",
    "\n",
    "Еще одна особенность ResNet, что в конце отсутствуют полносвязные слои, причина в том, что имеется уже и так довольно сложная нейронная сеть, в которой уже и так могла решиться задача, которая обычна перекладывается на полносвязный слой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://drive.google.com/uc?export=view&id=1qqbZ6iWZaD6LMjuIJ85mBGYpBwi0w-HL'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Распознование алфавита языка жестов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-13T13:43:12.168034Z",
     "iopub.status.busy": "2021-06-13T13:43:12.167532Z",
     "iopub.status.idle": "2021-06-13T13:43:12.309507Z",
     "shell.execute_reply": "2021-06-13T13:43:12.308732Z",
     "shell.execute_reply.started": "2021-06-13T13:43:12.167997Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import models, transforms, datasets\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-13T13:43:12.311052Z",
     "iopub.status.busy": "2021-06-13T13:43:12.310593Z",
     "iopub.status.idle": "2021-06-13T13:43:12.314933Z",
     "shell.execute_reply": "2021-06-13T13:43:12.314056Z",
     "shell.execute_reply.started": "2021-06-13T13:43:12.311016Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data_path = '../input/asl-alphabet/asl_alphabet_train/asl_alphabet_train/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим трансформации для тестового и обучающего датасета.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-13T13:43:12.316645Z",
     "iopub.status.busy": "2021-06-13T13:43:12.316163Z",
     "iopub.status.idle": "2021-06-13T13:43:12.324103Z",
     "shell.execute_reply": "2021-06-13T13:43:12.323365Z",
     "shell.execute_reply.started": "2021-06-13T13:43:12.316611Z"
    }
   },
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "#     transforms.RandomAffine(degrees=5, scale=(0.3, 1.1)), # аугументации\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим датасет и поделим его на обучение и валидацию.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-13T13:43:12.326798Z",
     "iopub.status.busy": "2021-06-13T13:43:12.326191Z",
     "iopub.status.idle": "2021-06-13T13:44:24.471051Z",
     "shell.execute_reply": "2021-06-13T13:44:24.470214Z",
     "shell.execute_reply.started": "2021-06-13T13:43:12.326766Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# данные разложены по папкам, берём из папок данные\n",
    "train_dataset = datasets.ImageFolder(train_data_path, transform=train_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-13T13:44:24.474012Z",
     "iopub.status.busy": "2021-06-13T13:44:24.473755Z",
     "iopub.status.idle": "2021-06-13T13:44:24.935799Z",
     "shell.execute_reply": "2021-06-13T13:44:24.934958Z",
     "shell.execute_reply.started": "2021-06-13T13:44:24.473986Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "val_dataset = datasets.ImageFolder(train_data_path, transform=test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-13T13:44:27.361008Z",
     "iopub.status.busy": "2021-06-13T13:44:27.360685Z",
     "iopub.status.idle": "2021-06-13T13:44:27.371892Z",
     "shell.execute_reply": "2021-06-13T13:44:27.37107Z",
     "shell.execute_reply.started": "2021-06-13T13:44:27.360977Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "num_train_samples = len(train_dataset)\n",
    "# num_train_samples = 20000\n",
    "\n",
    "val_split = 0.2\n",
    "split = int(num_train_samples * val_split)\n",
    "\n",
    "# перемешиваем индексы\n",
    "indices = torch.randperm(num_train_samples)\n",
    "\n",
    "train_subset = torch.utils.data.Subset(train_dataset, indices[split:])\n",
    "val_subset = torch.utils.data.Subset(val_dataset, indices[:split])\n",
    "\n",
    "len(train_subset), len(val_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-13T13:44:28.50381Z",
     "iopub.status.busy": "2021-06-13T13:44:28.503495Z",
     "iopub.status.idle": "2021-06-13T13:44:28.508395Z",
     "shell.execute_reply": "2021-06-13T13:44:28.507344Z",
     "shell.execute_reply.started": "2021-06-13T13:44:28.503784Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=train_subset, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=val_subset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-13T13:44:29.818678Z",
     "iopub.status.busy": "2021-06-13T13:44:29.81828Z",
     "iopub.status.idle": "2021-06-13T13:44:29.822822Z",
     "shell.execute_reply": "2021-06-13T13:44:29.821675Z",
     "shell.execute_reply.started": "2021-06-13T13:44:29.818649Z"
    }
   },
   "outputs": [],
   "source": [
    "classes = train_dataloader.dataset.dataset.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можем проверить, как работает dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-13T13:44:43.732922Z",
     "iopub.status.busy": "2021-06-13T13:44:43.73258Z",
     "iopub.status.idle": "2021-06-13T13:44:44.159856Z",
     "shell.execute_reply": "2021-06-13T13:44:44.159108Z",
     "shell.execute_reply.started": "2021-06-13T13:44:43.732887Z"
    }
   },
   "outputs": [],
   "source": [
    "for img, label in train_dataloader:\n",
    "    print(img.shape, label.shape)\n",
    "    print(f'Ground Truth {classes[label[0]]}')\n",
    "    plt.imshow(img[0].permute(1, 2, 0))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-06-13T13:44:32.351027Z",
     "iopub.status.busy": "2021-06-13T13:44:32.350703Z",
     "iopub.status.idle": "2021-06-13T13:44:43.73093Z",
     "shell.execute_reply": "2021-06-13T13:44:43.730124Z",
     "shell.execute_reply.started": "2021-06-13T13:44:32.350998Z"
    }
   },
   "outputs": [],
   "source": [
    "resnet = models.resnet50(pretrained=True)\n",
    "summary(resnet.to(device), input_size=(3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заморозим претренерованные слои, чтобы он не обучались.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-06-13T13:44:55.286912Z",
     "iopub.status.busy": "2021-06-13T13:44:55.286513Z",
     "iopub.status.idle": "2021-06-13T13:44:55.296196Z",
     "shell.execute_reply": "2021-06-13T13:44:55.295259Z",
     "shell.execute_reply.started": "2021-06-13T13:44:55.286877Z"
    }
   },
   "outputs": [],
   "source": [
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим кол-во параметров по слоям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-06-13T13:44:57.003751Z",
     "iopub.status.busy": "2021-06-13T13:44:57.003437Z",
     "iopub.status.idle": "2021-06-13T13:44:57.014741Z",
     "shell.execute_reply": "2021-06-13T13:44:57.013866Z",
     "shell.execute_reply.started": "2021-06-13T13:44:57.003721Z"
    }
   },
   "outputs": [],
   "source": [
    "resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам нужно переопределить последний слой т.к. у нас не 1000 классов как в ResNet.\n",
    "\n",
    "Для этого берём количество парамтеров, которое идёт на вход последнего линейного слоя и на выход даём количество классов и меняем в реснете на новый полносвязный слой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": false,
    "execution": {
     "iopub.execute_input": "2021-06-13T13:45:14.764803Z",
     "iopub.status.busy": "2021-06-13T13:45:14.764493Z",
     "iopub.status.idle": "2021-06-13T13:45:14.85672Z",
     "shell.execute_reply": "2021-06-13T13:45:14.855905Z",
     "shell.execute_reply.started": "2021-06-13T13:45:14.764775Z"
    }
   },
   "outputs": [],
   "source": [
    "in_features = resnet.fc.in_features\n",
    "fc = nn.Linear(in_features=in_features, out_features=len(classes))\n",
    "resnet.fc = fc\n",
    "\n",
    "summary(resnet.to(device), input_size=(3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь у нас на последнем слое не 1000, а 29 выходов и обучаем мы только последний слой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зададим функцию потерь и оптимизатор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-13T13:45:29.349491Z",
     "iopub.status.busy": "2021-06-13T13:45:29.349067Z",
     "iopub.status.idle": "2021-06-13T13:45:29.356534Z",
     "shell.execute_reply": "2021-06-13T13:45:29.3554Z",
     "shell.execute_reply.started": "2021-06-13T13:45:29.349455Z"
    }
   },
   "outputs": [],
   "source": [
    "# функция потерь\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# оптимизатор\n",
    "optimizer = torch.optim.Adam(resnet.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-13T13:45:31.296563Z",
     "iopub.status.busy": "2021-06-13T13:45:31.2962Z",
     "iopub.status.idle": "2021-06-13T13:45:31.312182Z",
     "shell.execute_reply": "2021-06-13T13:45:31.311204Z",
     "shell.execute_reply.started": "2021-06-13T13:45:31.296532Z"
    }
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def train(model,\n",
    "          criterion,\n",
    "          optimizer,\n",
    "          train_dataloader,\n",
    "          test_dataloader,\n",
    "          print_every,\n",
    "          num_epoch):\n",
    "    steps = 0\n",
    "    train_losses, val_losses = [], []\n",
    "\n",
    "    model.to(device)\n",
    "    for epoch in tqdm(range(num_epoch)):\n",
    "        running_loss = 0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        start_time = time()\n",
    "        iter_time = time()\n",
    "        \n",
    "        model.train()\n",
    "        # проходимся по обучающему датасету\n",
    "        for i, (images, labels) in enumerate(train_dataloader):\n",
    "            steps += 1\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            # получаем предсказания\n",
    "            output = model(images)\n",
    "            # считаем ошибку\n",
    "            loss = criterion(output, labels)\n",
    "\n",
    "            # насколько корректно всё предсказали\n",
    "            correct_train += (torch.max(output, dim=1)[1] == labels).sum()\n",
    "            # сколько всего объектов было в предсказании\n",
    "            total_train += labels.size(0)\n",
    "\n",
    "            # Backward and optimize - обучение\n",
    "            # обнуляем градиенты\n",
    "            optimizer.zero_grad()\n",
    "            # считаем градиенты\n",
    "            loss.backward()\n",
    "            # меняем веса\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Logging\n",
    "            if steps % print_every == 0:\n",
    "                print(f'Epoch [{epoch + 1}]/[{num_epoch}]. Batch [{i + 1}]/[{len(train_dataloader)}].', end=' ')\n",
    "                print(f'Train loss {running_loss / steps:.3f}.', end=' ')\n",
    "                print(f'Train acc {correct_train / total_train * 100:.3f}.', end=' ')\n",
    "                \n",
    "                # считаем, что происходит на валидации (градиент не трогаем - так быстрее)\n",
    "                with torch.no_grad():\n",
    "                    # переводим модель в режим валидации\n",
    "                    model.eval()\n",
    "                    correct_val, total_val = 0, 0\n",
    "                    val_loss = 0\n",
    "                    # проходимся по тестовому набору данных\n",
    "                    for images, labels in test_dataloader:\n",
    "                        images = images.to(device)\n",
    "                        labels = labels.to(device)\n",
    "                        # предсказания\n",
    "                        output = model(images)\n",
    "                        loss = criterion(output, labels)\n",
    "                        val_loss += loss.item()\n",
    "\n",
    "                        correct_val += (torch.max(output, dim=1)[1] == labels).sum()\n",
    "                        total_val += labels.size(0)\n",
    "\n",
    "                print(f'Val loss {val_loss / len(test_dataloader):.3f}. Val acc {correct_val / total_val * 100:.3f}.', end=' ')\n",
    "                print(f'Took {time() - iter_time:.3f} seconds')\n",
    "                iter_time = time()\n",
    "\n",
    "                train_losses.append(running_loss / total_train)\n",
    "                val_losses.append(val_loss / total_val)\n",
    "\n",
    "\n",
    "        print(f'Epoch took {time() - start_time}') \n",
    "        torch.save(model, f'checkpoint_{correct_val / total_val * 100:.2f}')\n",
    "        \n",
    "    return model, train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-13T13:45:32.467188Z",
     "iopub.status.busy": "2021-06-13T13:45:32.466861Z"
    }
   },
   "outputs": [],
   "source": [
    "# печатаем каждые 50 итераций\n",
    "print_every = 50\n",
    "# обучаем 2 эпохи (2 ч 15 мин)\n",
    "num_epoch = 2\n",
    "\n",
    "resnet, train_losses, val_losses = train(\n",
    "    model=resnet,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=val_dataloader,\n",
    "    print_every=print_every,\n",
    "    num_epoch=num_epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(val_losses, label='Validation loss')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инференс\n",
    "\n",
    "Посмотрим как работает на тестовых картинках, на которых модель не обучалась."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "test_data_path = Path('../input/asl-alphabet/asl_alphabet_test/asl_alphabet_test/')\n",
    "\n",
    "\n",
    "class ASLTestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root_path, transforms=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        # тестовы трансформации\n",
    "        self.transforms = transforms\n",
    "        # считываем все пути до картинок\n",
    "        self.imgs = sorted(list(Path(root_path).glob('*.jpg')))\n",
    "        \n",
    "    def __len__(self):\n",
    "        # сколько всего есть картинок\n",
    "        return len(self.imgs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # получаем объекты по индексу\n",
    "        img_path = self.imgs[idx]\n",
    "        # открываем картинку\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        # в названии картинки хранится класс, извекаем его с помощью сплита\n",
    "        label = img_path.parts[-1].split('_')[0]\n",
    "        if self.transforms:\n",
    "            # если есть трансформация - применяем её\n",
    "            img = self.transforms(img)\n",
    "        \n",
    "        # возвращаем картинку и класс\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# инициализируем тестовый датасет с тестовыми трансформациями\n",
    "test_dataset = ASLTestDataset(test_data_path, transforms=test_transforms)\n",
    "\n",
    "columns = 7\n",
    "row = round(len(test_dataset) / columns)\n",
    "\n",
    "fig, ax = plt.subplots(row, columns, figsize=(columns * row, row * columns))\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.2)\n",
    "\n",
    "i, j = 0, 0\n",
    "# проходимся по тестовому датасету и визуализируем,\n",
    "# что предсказала модель и что должна была предсказать\n",
    "for img, label in test_dataset:\n",
    "    img = torch.Tensor(img)\n",
    "    img = img.to(device)\n",
    "    resnet.eval()\n",
    "    prediction = resnet(img[None])\n",
    "\n",
    "    ax[i][j].imshow(img.cpu().permute(1, 2, 0))\n",
    "    ax[i][j].set_title(f'GT {label}. Pred {classes[torch.max(prediction, dim=1)[1]]}')\n",
    "    ax[i][j].axis('off')\n",
    "    j += 1\n",
    "    if j == columns:\n",
    "        j = 0\n",
    "        i += 1\n",
    "        \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
