{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Расскажите, как работает регуляризация в решающих деревьях, какие параметры мы штрафуем в данных алгоритмах?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответ**: Регуляризация используется для снижения переобучения модели.\n",
    "\n",
    "В решающем дереве (Deceision Tree), поскольку это эвристический метод, нет как таковой функции потерь и использование L1 и L2 регуляризации проблематично. Поэтому в Deceision Tree модели используют другие методы регуляризации:\n",
    "\n",
    "- max_depths - глубина дерева, max_leaves - количество листьев и пр.\n",
    "- Стрижка деревьев - при этом методе удаляются листья дерева у которых снижение критерия информативности (impurity criterion) ниже порогового значения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. По какому принципу рассчитывается \"важность признака (feature_importance)\" в ансамблях деревьев?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответ**: Существуют следующие способы расчета важности признаков (feature importance) в ансамблях деревьев:\n",
    "\n",
    "- Способ который иногда называют \"важностью Джини\" или \"средним уменьшением примеси (изменчивости)\". Способ заключается в подсчете суммарного снижения информативности (impurity) узлов с весами которые рассчитываются для каждого узла как отношение примеров достигших данного узла к общему количетву примеров в обучающей выборке. Итоговая важность признаков расчитыватся усреднением по всем деревьям ансамбля.\n",
    "- Второй способ определения важности признаков заключается в определении эффекта исключения признаков и оценке снижения результирующей точности модели.\n",
    "\n",
    "---\n",
    "\n",
    "В литературе описываются следующие методы вычисления важности признаков в алгоритмах ансамблей деревьев:\n",
    "- MDI (Mean Decrease in Impurity, Gini Importance). Чем больше, тем выше важность. Данный метод уменьшает количество значений в признака и вычисляет точность модели после изменений. Чем сильнее уменьшение точности модели, тем выше важность признака. Может некорректно отображать важность, если признак содержит большое количество уникальных значений.\n",
    "- MDA (Mean Decrease in Accuracy, Permutation Importance). Данный метод перемешивает значения в признаке и измеряет точность модели. В отличие от MDI не имеет проблем с признаками с большим количеством уникальных значений.\n",
    "- Boruta. Данный метод так же как MDA перемешивает значения в признаках, но перемешанные данные добавляются в основной датасет.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
