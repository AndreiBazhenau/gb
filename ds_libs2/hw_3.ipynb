{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Для чего и в каких случаях полезны различные варианты усреднения для метрик качества классификации: micro, macro, weighted?\n",
    "\n",
    "**micro**: метрики вычисляются глобально, т.е. для каждого класса суммируются полные истинные положительные значения, ложные негативные и ложные позитивные срабатывания. Micro усреднение полезно для оценки несбалансированных выборок. Полезно использовать, когда важно оценить качество классификатора на данных, в которых присутствуют классы небольшого размера и верное предсказание этих классов критично.\n",
    "\n",
    "**macro**: для каждого класса метрики находятся раздельно, после чего берется их невзвешенное значение. Этот вариант не учитывает дисбаланс метрик. Macro усреднение полезно, когда вы хотите узнать, как система работает в целом по наборам данных. Полезно использовать, когда необходимо оценить максимальное качество работы классификатора и при этом качество предсказаний миноритарного класса не критично.\n",
    "\n",
    "**weighted**: показатели для каждого класса рассчитываются отдельно, затем  находится среднее взвешенное значение. Этот вариант позволяет учитывать дисбаланс метрик. Weighted усреднение полезно оценивать, если в наборе данных разным классам присваивается разный вес (значимость)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. В чём разница между моделями xgboost, lightgbm и catboost или какие их основные особенности?\n",
    "\n",
    "Общее то, что это различные реализации алгоритма градиентного бустинга на решающих деревьях (GBM).\n",
    "\n",
    "**XGBoost** - это eXtreme Gradient Boosting, т.е. в основе данной модели лежит градиентный бустинг. XGBoost посчитывает похожеть между элементами и производит стрижку результирующих деревьев, основываясь на гиперпараметр гамма. Прирост информации в XGBoost подсчитывается, как разница между суммой веток и вершины. XGBoost использует предварительно отсортированный алгоритм и алгоритм на основе гистограммы для вычисления наилучшего разделения (pre-sorted algorithm & Histogram-based algorithm). XGBoost не может обрабатывать категориальные функции, в отличие от CatBoost или LightGBM.\n",
    "\n",
    "**LightGBM** - это облегченная версия градиентного бустинга, которая заостряет внимание на ошибках и не использует всю выборку. Также, эта модель группирует разреженные признаки, типичные для бинарного формата машинного обучения, а также признаки с близкими диапазонами значений. LightGBM использует технику односторонней выборки на основе градиента (GOSS - Gradient-based One-Side Sampling) для фильтрации экземпляров данных для нахождения значения разделения. Каждое следующее дерево, в рамках бустинга, обучается не на всех данных, а в основном на тех, которые дают наибольшую ошибку (отбирается доля данных с наибольшей ошибкой и небольшая доля нормальных данных. leaf-wise growth - дерево растет в глубину только на листьях с высокой энтропией. Перед построением набора данных для LGBM необходимо преобразовать категориальные функции в тип int. Он не принимает строковые значения, даже если вы передаете его через параметр `categorical_feature`. Exclusive Feature Bundling (EFB) - признаки, которые можно объединять без потери информации, объединяются. Для уменьшения размера использованной памяти желательно перенумеровать значения категориальных признаков, чтобы они шли непрерывно от 0 до максимального значения. Иначе если категориальный признак может принимать большие значения, то для каждого решающего правила для этого признака будет создано битовое поле размером до 12564 байт.\n",
    "\n",
    "**Catboost** - это быстрая модель градиентного бустинга, построенная на симметричных разветвлениях. Выдерживая симметрию, модель решает проблемы классификации быстрее аналогов. В дополнение, эта модель сама переводит признаки в нужный формат без использования функции get_dummies и имеет встроенные алгоритмы, препятствующие переобучению. Это достигается высоким уровнем рандома выборки и большей объективностью при оценке моделей (ошибка считается по данным, на которых модель не обучалась). По умолчанию CatBoost воспринимает как категориальные признаки только с 2-мя уникальными значениями. Если признак имеет больше чем 2 уникальных значения, то он будет считаться не категорийным. Для изменения этого поведения необходимо использовать параметр one_hot_max_size.\n",
    "\n",
    "LightGBM и Catboost имеют преимущество в скорости работе по сравнению с XGBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/func_compare.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/tree_grows_examples.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Сравнение скорости работы**\n",
    "\n",
    "<img src=\"img/training_speed.png\">\n",
    "\n",
    "https://medium.com/riskified-technology/xgboost-lightgbm-or-catboost-which-boosting-algorithm-should-i-use-e7fda7bb36bc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
